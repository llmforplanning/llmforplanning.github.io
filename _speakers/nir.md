---
# Name of the speaker
name: Nir Lipovetzky

# Link to the speaker's webpage
webpage: https://nirlipo.github.io/

# Primary affiliation of the speaker
affil:  The University of Melbourne
# Link to the speaker's primary affiliation
affil_link: https://www.unimelb.edu.au/

# An image of the speaker (square aspect ratio works the best) (place in the `assets/img/speakers` directory)
img: nir.jpg

---

<!-- Whatever you write below will show up as the speaker's bio -->

<!-- Christian is an Assistant Professor at Queen's University in Kingston, Canada. He completed his PhD under the supervision of Professors Sheila McIlraith and J. Christopher Beck in the area of Automated Planning, with the Knowledge Representation and Reasoning Group at the University of Toronto. Following his PhD, he was a post-doc for two years with the University of Melbourne's Agentlab studying techniques for multi-agent planning with a project on human-agent collaboration, and then subsequently a Research Fellow with the MERS group at MIT's CSAIL. Just prior to joining Queen's he was a Research Staff Member for two years at the MIT-IBM Watson AI Lab. -->

Towards Model-Based Reasoning in Large Language Models: A Planning Perspective

**Bio**: 
Nir Lipovetzky is an Associate Professor in the School of Computing and Information Systems at the University of Melbourne. His research spans artificial intelligence (AI) planning, heuristic search, learning, verification, and intention recognition, with a particular focus on developing novel approaches to inference in sequential decision-making problems. He contributes to several AI planning initiatives, including the Lightweight Automated Planning ToolKiT (LAPKT), designed to simplify the creation and extension of automated planners; Planimation, a platform for visualising plans using declarative programming; and planning.domains, a widely used suite of tools for teaching AI planning. He is passionate about building bridges between AI planning and other research areas.

**Abstract**:
Large Language Models (LLMs) are powerful at generating text, code, and explanations, yet when it comes to structured reasoning, they often provide incorrect responses. In this talk, we explore how ideas from automated planning can help LLMs find structure in queries. We begin with Planning in the Dark, where LLMs infer planning models from natural language, and their non-determinism becomes a feature rather than a flaw with the restraints of conformal prediction and symbolic planners. Next, through Planning-Driven Programming, we show how planning-inspired techniques can guide LLMs to iteratively refine code through reasoning and verification steps. Finally, we turn to the Abstraction and Reasoning Corpus (ARC), demonstrating how planning and knowledge augmentation can enhance compositional reasoning and generalisation beyond training data. Research in AI planning outlines a path toward LLMs that don't just generate the next token, but also plan, reason, and generalise with the assistance of model based planning solvers.
